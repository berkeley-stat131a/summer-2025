[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "STAT c131a: Statistical Methods for Data Science",
    "section": "",
    "text": "Sections 1 and 2 here",
    "crumbs": [
      "Main"
    ]
  },
  {
    "objectID": "index.html#installing-rstudio-on-your-machine",
    "href": "index.html#installing-rstudio-on-your-machine",
    "title": "STAT c131a: Statistical Methods for Data Science",
    "section": "",
    "text": "Sections 1 and 2 here",
    "crumbs": [
      "Main"
    ]
  },
  {
    "objectID": "index.html#core-tools",
    "href": "index.html#core-tools",
    "title": "STAT c131a: Statistical Methods for Data Science",
    "section": "Core tools",
    "text": "Core tools\n\n\n    \n         DataHub\n    \n    Write code\n    \n\n    \n         PingPong\n    \n    Chatbot coach for writing code\n    \n\n    \n         Gradescope\n    \n    Submit assignments, see grades\n    \n\n    \n         Ed\n    \n    Ask questions about course material\n    \n\n    \n         Lecture Recordings\n    \n    (Youtube Playlist)\n    \n\n    \n         Textbook\n    \n    Additional reference and lessons\n    \n\nNo matching items\n\nFor all other questions or requests, contact Prof Wetchler directly - wetchler@berkeley.edu",
    "crumbs": [
      "Main"
    ]
  },
  {
    "objectID": "index.html#course-staff",
    "href": "index.html#course-staff",
    "title": "STAT c131a: Statistical Methods for Data Science",
    "section": "Course Staff",
    "text": "Course Staff\n\n\n\n\n\n\n\n\n\nPosition\nName\nOffice Hours\nEmail\n\n\n\n\nInstructor\nEverett Wetchler\n1. Tu/W/Th 12:30-1, Evans 323 (my office)2. Tu/W/Th After class (quick questions)3.By appointment (email me)\nwetchler@berkeley.edu\n\n\nGSI (runs lab)\nHuong Vu\nMondays 9-11am, Zoom link\nhuong_vu@berkeley.edu\n\n\nReader (grading)\nSarah Sturgeon",
    "crumbs": [
      "Main"
    ]
  },
  {
    "objectID": "index.html#where-and-when-we-meet-office-hours",
    "href": "index.html#where-and-when-we-meet-office-hours",
    "title": "STAT c131a: Statistical Methods for Data Science",
    "section": "Where and when we meet + Office Hours",
    "text": "Where and when we meet + Office Hours",
    "crumbs": [
      "Main"
    ]
  },
  {
    "objectID": "index.html#more-office-hours",
    "href": "index.html#more-office-hours",
    "title": "STAT c131a: Statistical Methods for Data Science",
    "section": "More office hours",
    "text": "More office hours\n\nGSI (Huong) - Mondays 9-11am, Evans 434\nEverett by appointment - email me",
    "crumbs": [
      "Main"
    ]
  },
  {
    "objectID": "index.html#week-schedule",
    "href": "index.html#week-schedule",
    "title": "STAT c131a: Statistical Methods for Data Science",
    "section": "8-week Schedule",
    "text": "8-week Schedule",
    "crumbs": [
      "Main"
    ]
  },
  {
    "objectID": "index.html#content",
    "href": "index.html#content",
    "title": "STAT c131a: Statistical Methods for Data Science",
    "section": "Content",
    "text": "Content\n\n\n  \n  Week 1 - Intro, R and RStudio, Data Visualization, Data Wrangling\n  \n  \n\n  \n    \n    June 24\n    \n    \n    Getting Started\n    \n      \n      \n    \n     \n    \n      \n        \n        \n        Lec01 Slides\n        \n                 \n      \n        \n        \n        Lec01 Video\n        \n                 \n      \n        \n        \n        Assignment: Lab 00\n        \n                 \n      \n        \n        \n        Assignment: Course pre-survey\n        \n                 \n      \n    \n    \n    \n    \n  \n    \n    June 25\n    \n    \n    Data Visualization\n    \n      \n      \n    \n     \n    \n      \n        \n        \n        Pre-reading A\n        \n                 \n      \n        \n        \n        Pre-reading B (Ch 1-3)\n        \n                 \n      \n        \n        \n        Code-Along (lectures/Lab02_CodeAlong.Rmd)\n        \n                 \n      \n        \n        \n        Lec02 Video\n        \n                 \n      \n        \n        \n        Assignment: Lab 01 (due Monday 6/30 midnight)\n        \n                 \n      \n    \n    \n    \n    \n  \n    \n    June 26\n    \n    \n    Data Wrangling\n    \n      \n      \n    \n     \n    \n      \n        \n        \n        Code-Along (lectures/Lab03_CodeAlong.Rmd)\n        \n                 \n      \n        \n        \n        Lec03 Video\n        \n                 \n      \n        \n        \n        \n        \n                 \n      \n    \n    \n    \n    \n  \n  \n  \n  \n  Resources\n  \n  \n    \n      tidyverse documentation (ggplot, dplyr, stringr, forcats, etc)\n    \n      Tour of RStudio\n    \n      Markdown Cheatsheet\n    \n      R beginner tutorials\n    \n      Data Viz online book\n    \n  \n  \n  \n  \n  \n\n  \n  Week 2 - Statistical testing with and without math\n  \n  \n\n  \n    \n    July 1\n    \n    \n    What is \"statistical significance\"?\n    \n     \n    \n      \n        \n        \n        Lec04 Slides\n        \n                 \n      \n        \n        \n        Lec04 Video\n        \n                 \n      \n        \n        \n        Code-Along (lectures/Lec04_CodeAlong.Rmd)\n        \n                 \n      \n    \n    \n    \n    \n  \n    \n    July 2\n    \n    \n    Statistical testing with simulation, not math.\n    \n     \n    \n      \n        \n        \n        Lec05 Slides\n        \n                 \n      \n        \n        \n        Lec05 Video\n        \n                 \n      \n        \n        \n        Pre-reading (Ch 3.1-3.3 and 3.8). Note: this book uses *outdated* coding syntax, so only skim the code parts.\n        \n                 \n      \n        \n        \n        Assignment: Lab 03 (due Tuesday 7/8 midnight)\n        \n                 \n      \n    \n    \n    \n    \n  \n    \n    July 3\n    \n    \n    The Math of Statistics\n    \n     \n    \n      \n        \n        \n        Pre-reading (Ch 3.4, 3.6, 3.7)\n        \n                 \n      \n        \n        \n        Lec06 Video (Disclaimer: this wasn't a very good lecture. I was so tired y'all...)\n        \n                 \n      \n        \n        \n        Assignment: Lab 04 (due Wednesday 7/9 midnight)\n        \n                 \n      \n        \n        \n        (No slides today)\n        \n                 \n      \n    \n    \n    \n    \n  \n  \n  \n  \n  Resources\n  \n  \n    None this week\n  \n  \n  \n  \n  \n\n  \n  Week 3 - Probability, Correlation, Practice\n  \n  \n\n  \n    \n    July 8\n    \n    \n    Data Science in Context\n    \n     \n    \n      \n        \n        \n        Lec07 Slides\n        \n                 \n      \n        \n        \n        Lec07 Video\n        \n                 \n      \n        \n        \n        Assignment: Lab 05 (due Saturday 7/12 midnight)\n        \n                 \n      \n    \n    \n    \n    \n  \n    \n    July 9\n    \n    \n    Probability\n    \n     \n    \n      \n        \n        \n        Lec08 Slides\n        \n                 \n      \n        \n        \n        Lec08 Video\n        \n                 \n      \n    \n    \n    \n    \n  \n    \n    July 10\n    \n    \n    Correlation\n    \n     \n    \n      \n        \n        \n        Worksheet - Dog Breeds - See Gradescope (due Sunday 7/13 midnight)\n        \n                 \n      \n        \n        \n        (No slides)\n        \n                 \n      \n        \n        \n        (No video)\n        \n                 \n      \n    \n    \n    \n    \n  \n  \n  \n  \n  Resources\n  \n  \n    \n      Wikipedia on stop-and-frisk\n    \n      NYC website with the truly 'raw' data\n    \n  \n  \n  \n  \n  \n\n  \n  Week 4 - Correlation, Midterm\n  \n  \n\n  \n    \n    July 15\n    \n    \n    Correlation Continued\n    \n     \n    \n      \n        \n        \n        Lec10 Slides\n        \n                 \n      \n        \n        \n        Lec10 Video\n        \n                 \n      \n        \n        \n        Assignment: Lab 06 (due Sunday 7/20 midnight)\n        \n                 \n      \n    \n    \n    \n    \n  \n    \n    July 16\n    \n    \n    Midterm Review, Coding Mini-Lecture\n    \n     \n    \n      \n        \n        \n        Lec11 Slides\n        \n                 \n      \n        \n        \n        Lec11 Video\n        \n                 \n      \n        \n        \n        Probability Practice (Ungraded)\n        \n                 \n      \n    \n    \n    \n    \n  \n    \n    July 17\n    \n    \n    Midterm\n    \n     \n    \n      \n        \n        \n        Midterm Solution\n        \n                 \n      \n    \n    \n    \n    \n  \n  \n  \n  \n  Resources\n  \n  \n    \n      Guess the Correlation\n    \n  \n  \n  \n  \n  \n\n  \n  Week 5 - Begin modeling, linear regression\n  \n  \n\n  \n    \n    July 22\n    \n    \n    (No class)\n    \n     \n    \n    \n    \n    \n  \n    \n    July 23\n    \n    \n    Midterm debrief and practice\n    \n     \n    \n      \n        \n        \n        Lec12 Slides\n        \n                 \n      \n        \n        \n        Midterm Common Errors (code demo)\n        \n                 \n      \n        \n        \n        Lec12 Video\n        \n                 \n      \n        \n        \n        Assignment: Lab 07 (due Sunday 7/27 midnight)\n        \n                 \n      \n    \n    \n    \n    \n  \n    \n    July 24\n    \n    \n    Introduction to modeling\n    \n     \n    \n      \n        \n        \n        Lec13 Slides\n        \n                 \n      \n        \n        \n        Lec13 Video\n        \n                 \n      \n        \n        \n        Assignment: Lab 08 (due Tuesday 7/29 midnight)\n        \n                 \n      \n    \n    \n    \n    \n  \n  \n  \n  \n  Resources\n  \n  \n    None this week\n  \n  \n  \n  \n  \n\n  \n  Week 6 - Regression and personally-relevant datasets\n  \n  \n\n  \n    \n    July 29\n    \n    \n    Linear Regression\n    \n     \n    \n      \n        \n        \n        Lec14 Slides\n        \n                 \n      \n        \n        \n        Code Demo\n        \n                 \n      \n        \n        \n        Lec14 Video\n        \n                 \n      \n        \n        \n        Assignment: Choose your dataset(s) (due Thu 7/31 END OF CLASS)\n        \n                 \n      \n        \n        \n        Assignment: Lab 09 (due Fri 8/1 midnight)\n        \n                 \n      \n    \n    \n    \n    \n  \n    \n    July 30\n    \n    \n    Getting more from your data\n    \n     \n    \n      \n        \n        \n        Lec15 Slides\n        \n                 \n      \n        \n        \n        Code Demo\n        \n                 \n      \n        \n        \n        Lec15 Video\n        \n                 \n      \n    \n    \n    \n    \n  \n    \n    July 31\n    \n    \n    Getting acquainted with your data\n    \n     \n    \n      \n        \n        \n        Assignment: Lab 10 (due Mon 8/4 midnight)\n        \n                 \n      \n        \n        \n        No Slides\n        \n                 \n      \n        \n        \n        No Video\n        \n                 \n      \n    \n    \n    \n    \n  \n  \n  \n  \n  Resources\n  \n  \n    \n      Installing R and RStudio on your computer (parts 1 and 2)\n    \n      Other useful tutorials by Gaston Sanchez (scroll down to 'R Textbooks')\n    \n  \n  \n  \n  \n  \n\n  \n  Week 7 - More models, better models\n  \n  \n\n  \n    \n    Aug 5\n    \n    \n    Logistic Regression\n    \n     \n    \n      \n        \n        \n        Lec17 Slides\n        \n                 \n      \n        \n        \n        Code Demo\n        \n                 \n      \n        \n        \n        Lec17 Video\n        \n                 \n      \n        \n        \n        Assignment: Logistic Regression (due Thu Aug 7 midnight)\n        \n                 \n      \n        \n        \n        Tutorial on logarithms\n        \n                 \n      \n    \n    \n    \n    \n  \n    \n    Aug 6\n    \n    \n    Classifier Evaluation\n    \n     \n    \n      \n        \n        \n        Lec18 Slides\n        \n                 \n      \n        \n        \n        Lec18 Video\n        \n                 \n      \n        \n        \n        Code Demo\n        \n                 \n      \n        \n        \n        OPTIONAL Assignment: Classifier Evaluation\n        \n                 \n      \n    \n    \n    \n    \n  \n    \n    Aug 7\n    \n    \n    Honest Models (Cross-Validation)\n    \n     \n    \n      \n        \n        \n        Lec19 Slides\n        \n                 \n      \n        \n        \n        Lec19 Video\n        \n                 \n      \n        \n        \n        Code Demo\n        \n                 \n      \n        \n        \n        Assignment: Kaggle Modeling Competition! Prizes! (Due Tue Aug 10 midnight)\n        \n                 \n      \n    \n    \n    \n    \n  \n  \n  \n  \n  Resources\n  \n  \n    \n      Logarithms Tutorial Video\n    \n  \n  \n  \n  \n  \n\n  \n  Week 8 - The Home Stretch\n  \n  \n\n  \n    \n    Aug 12\n    \n    \n    Lab Work Time\n    \n     \n    \n      \n        \n        \n        Lec20 Slides\n        \n                 \n      \n        \n        \n        Lec20 Video\n        \n                 \n      \n        \n        \n        Code Demo from last week\n        \n                 \n      \n    \n    \n    \n    \n  \n    \n    Aug 13\n    \n    \n    Final Review Session\n    \n     \n    \n      \n        \n      \n        \n      \n    \n    \n    \n    \n  \n    \n    Aug 14\n    \n    \n    Final Exam\n    \n     \n    \n    \n    \n    \n  \n  \n  \n  \n  Resources\n  \n  \n    None this week\n  \n  \n  \n  \n  \n\nNo matching items\n\nThis work is licensed under a Creative Commons Attribution 4.0 International License.",
    "crumbs": [
      "Main"
    ]
  },
  {
    "objectID": "competition.html",
    "href": "competition.html",
    "title": "Kaggle Competition (Lab 13)",
    "section": "",
    "text": "Foreword - there is a template\nOpen datahub to lab13/ or look here on github. This is optional, but a useful outline to help you with the mechanics of Kaggle submission. In case it helps.\n\n\nA. What to submit on Kaggle\nFollow the instructions on the competition page. You “submit” your predictions for all data in the test set. Note that each row in the test set has an id column (numbered from 2001 to 4000). You need to include these ids in your prediction file, which should look like the table below (you can also see a sample submission file on Kaggle). For example, the table below shows that for the test row with id 2001, your model predicts a happiness score of 1.9123. For the row with id 2002, your model predicts 3.3825. And so forth.\n\n\n\nid\nhappiness\n\n\n\n\n2001\n1.9123\n\n\n2002\n3.3825\n\n\n…\n…\n\n\n3999\n3.1747\n\n\n4000\n2.0903\n\n\n\n\n\nB. What to submit on Gradescope\n1) Explorations of the data\nYou shouldn’t need to clean the data much. It’s all complete (no NAs) and modified to be very readable and tidy. But feel free to do any additional steps that make it more usable to you.\nBut DO explore all of the variables. Their distributions (bar plots or scatterplots etc), and correlations with the DV (happiness), and anything else that helps you intuitively “understand” what’s going on here.\nAlso note that for categorical variables (like race or marital), a simple correlation with happiness doesn’t work because a categorical variable really turns into multiple binary variables. Instead, you can fit a linear model predicting happiness from only that variable, and look at the r² (and the model coefficients, to see the direction that each category pushes the prediction). You can compare this r² to the correlation (r) values from continuous variables by just squaring their correlation coefficients to get r² values (or you could fit linear models for each of them and get r² directly – either way). You could then rank all of the variables by their r² values, as an initial estimate of how useful they are in modeling.\n2) Build models and score with cross-validation\nSee the demos in Lecture19_CodeDemo.Rmd (also should be visible on DataHub) for how to do train/test splits. At minimum, whenever you fit a model, first record the r² from the model summary or glance – this is your “in sample” r², scored on the same data you fit it on. Then have it predict on some data it hasn’t seen to get your “out of sample” r².\n3) Make a table of model performances using the above results\nCreate something like this, based on the results of the various models you try:\n\n\n\n\n\n\n\n\nModel\nIn-sample R²\nOut-of-sample R²\n\n\n\n\nhappiness ~ race + sex\n0.103\n0.085\n\n\nhappiness ~ race + sex + income\n0.145\n0.131\n\n\n…\n…\n…\n\n\nhappiness ~ race*sex + income + marital + age + employment\n0.201\n0.165\n\n\n\n4) Submission\nSubmit a pdf of your code including everything you’ve done, right down to the last step of writing out your predictions (from your best model) to a csv file that you will submit to Kaggle. See previous section, but be sure it has two columns: id and happiness.",
    "crumbs": [
      "Kaggle Competition"
    ]
  },
  {
    "objectID": "license.html",
    "href": "license.html",
    "title": "License",
    "section": "",
    "text": "This work is licensed under a Creative Commons Attribution 4.0 International License."
  },
  {
    "objectID": "assignments.html",
    "href": "assignments.html",
    "title": "Assignments",
    "section": "",
    "text": "Submit on Gradescope\nYou can find all assignments (and posted solutions) on Datahub Or you can look at the Github repository directly.\n\n\n\n\nAssignment\nDue date\nSolution*\n\n\n\n\nCourse Pre-Survey\nTue June 24 11:59pm\nn/a\n\n\nLab 00 - RStudio Intro\nTue June 24 11:59pm\nn/a\n\n\nLab 01 - Data Visualization\nMon June 30 11:59pm\npdf\n\n\nLab 02 - Data Wrangling\nTue July 1 11:59pm\npdf\n\n\nLab 03 - Permutation Testing\nWed July 8 11:59pm\npdf\n\n\nLab 04 - Randomness and Distributions\nThu July 9 11:59pm\npdf\n\n\nLab 05 - What’s going on in NYC?\nSat July 12 11:59pm\npdf\n\n\nWorksheet - Dog Breeds\nSun July 13 11:59pm\n-\n\n\nLab 06 - Correlation\nSun July 20 11:59pm\n-\n\n\nProbability Quick Practice\n(Ungraded, no submission)\ndoc\n\n\nMidterm\n(in-class Thu July 17)\npdf\n\n\nLab 07 - Post-Midterm Practice\nSun July 27\n-\n\n\nLab 08 - Intro to Modeling\nTue July 29\n-\n\n\nDataset Finding\nFri Aug 1\nSee Ed\n\n\nLab 09 - Regression\nFri Aug 1\n-\n\n\nLab 10 - Getting acquainted with your data\nMon Aug 4\n-\n\n\nLab 11 - Logistic Regression\nFri Aug 8\n-\n\n\nLab 12 - OPTIONAL - Classifier Evaluation\nSun Aug 10\n-\n\n\nLab 13 - Kaggle Competition\nTue Aug 12\n-\n\n\n\n* I call these “solutions,” but there are always many ways to solve any problem. Don’t look at these as “THE right way” to do it, just one way that you might learn something from.",
    "crumbs": [
      "Assignments"
    ]
  },
  {
    "objectID": "staff.html",
    "href": "staff.html",
    "title": "🍎 Staff",
    "section": "",
    "text": "The teaching staff is excited to have you in 131A!\n\n\n\n Instructor: Josh Grossman Please call me “Josh”! No need for “Professor”, “Dr.”, “Sir”, etc.  jdgg at berkeley dot edu    \n\n\n GSI: Van Hovenga vhovenga at berkeley dot edu      \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nIn general, please use Ed to communicate with the course staff.\nUnless otherwise indicated, email should only be used for private concerns directed to a specific member of the teaching staff."
  },
  {
    "objectID": "syllabus.html",
    "href": "syllabus.html",
    "title": "Syllabus",
    "section": "",
    "text": "SYLLABUS STILL UNDER CONSTRUCTION\n\nGrading:\n\n\n\nComponent\nFraction\nNotes\n\n\n\n\nAttendance\n10%\nAttend 80% of classes for full credit\n\n\nLabs/Homework\n20%\nTwo lowest grades dropped\n\n\nMidterm\n30%\n\n\n\nFinal\n40%\n\n\n\n\n\n\nCurving\nThis class is not curved. However, I may curve upwards if the exams prove harder than I intended. I design exams fresh every semester, so it’s hard to perfectly calibrate their difficulty.\n\n\nLetter grades\nWe follow the standard university grading system. 97% = A+, 93% = A, 90% = A-, 87% = B+, etc\n\n\nLaptop policy\nLaptops closed during lecture unless otherwise indicated.\n\n\nAssignments and late policy\n\nYou can submit assignments up to THREE DAYS late, with a penalty of 10% per day late.\nI drop your two lowest assignments in grading\n\n\n\nAttendance\nMeasured through an attendance check in the middle of lecture. Don’t sweat missing a class here and there, you’ll get full credit if you attend 80% of classes.\n\n\nLecture recordings\nWill be posted after class, see main page.\n\n\nOffice Hours\nSee Main page\n\n\nCollaboration policy\nAll assignments are individual assignments unless otherwise indicated. However, you can ask other students for help with specific questions or to better understand something in general - you just can’t do the assignment together.\n\n\nLate Assignments\nAll assignments are worth 10 points. For every day late (up to 1 week) you lose 1 point off the top.\n\n\nExams\n\nMidterm: July 17 (review day in class on July 16)\nFinal (cumulative): August 14 (review day in class on August 13)\n\n\n\nEven more resources\nEverything you need to know for Stat 131a will be covered in lectures, labs, and assignments. However, most of the course material is covered by the online textbook developed specifically for 131A.\n\nYou can find the textbook here or on the homepage\n\nOther resources that may be helpful:\n\nR beginner tutorials\nMarkdown Cheatsheet\nData Viz online book\nStatQuest YouTube Channel\n\nStatQuest provides videos on many of the topics we will cover in class. The instructor is very entertaining!\n\nR for Data Science, by Garrett Grolemund and Hadley Wickham. This is a free online book that covers the tidyverse set of R packages.\nTheory Meets Data by Ani Adhikari. This is the online book for STAT 88 that covers introductory probability at the level of Stat 20.",
    "crumbs": [
      "Syllabus"
    ]
  },
  {
    "objectID": "data.html",
    "href": "data.html",
    "title": "Data",
    "section": "",
    "text": "[UNDER CONSTRUCTION]\nWe’ll use data from several real world situations in class."
  },
  {
    "objectID": "data.html#data-1",
    "href": "data.html#data-1",
    "title": "Data",
    "section": "Data 1",
    "text": "Data 1"
  },
  {
    "objectID": "data.html#data-2",
    "href": "data.html#data-2",
    "title": "Data",
    "section": "Data 2",
    "text": "Data 2"
  }
]